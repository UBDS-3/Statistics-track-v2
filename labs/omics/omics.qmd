---
title: "Lab5: Omics"
author: "Bio Data Science^3"
date: "July 19 - August 2, 2025"
format: 
  html:
    toc: true 
    code-fold: false
    code-tools: true
    embed-resources: true
    highlight-style: github
    code-line-numbers: false 
params:
  solve: true
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warnging = FALSE) 
```

# scRNA-seq analysis

## Preamble

### Dependencies

```{r load-libs}
library(dplyr)
library(scran)
library(scran)
library(scater)
library(igraph)
library(ggplot2)
library(muscData)
library(pheatmap)
library(ExperimentHub)
```

```{r load-libs-hide, echo=FALSE}
library(patchwork)
```

### Data retrieval

```{r load-data}
eh <- ExperimentHub()
q <- query(eh, "Kang18")
(sce <- eh[[q$ah_id]])
```

## Preprocessing

### Quality control

```{r qc}
sce <- sce[rowSums(counts(sce) > 0) > 0, ]
sce <- addPerCellQC(sce)
sce <- sce[, !isOutlier(sce$detected, nmads=2, log=TRUE)]
sce <- sce[rowSums(counts(sce) > 1) >= 10, ]
```

### Feature selection

For each gene, we compute the variance and mean of the log-expression values. A trend is fitted to the variance against the mean for all genes. The fitted value for each gene is used as a proxy for the technical component of variation for each gene, under the assumption that most genes exhibit a low baseline level of variation that is not biologically interesting. The biological component of variation for each gene is defined as the the residual from the trend. (see `?modelGeneVar`)

```{r sel}
# log-library size normalization
sce <- logNormCounts(sce) 
# model gene expr. mean vs. var.
df <- modelGeneVar(sce) 
head(df)
```

> Use `dplyr` to filter the above gene-level statistics (`df`) for genes the 2,000 genes with the highest `bio`logical variance component.

```{r fil}
#| echo: !expr params$solve
fd <- df |>
    data.frame() |>
    arrange(bio) |>
    tail(n=2e3)
# or...
fd <- df |>
    data.frame() |>
    arrange(desc(bio)) |>
    head(n=2e3)
# or...
fd <- df |>
    data.frame() |>
    slice_max(bio, n=2e3)
```

> Reproduce the below scatter plot (`geom_point()`) of gene expression `mean`s vs. `total` variance estimates. You will need a 2nd layer to highlight the top-2,000 genes selected above (red points), and a 3rd layer to add the `tech`nical variance estimate (blue dashed line).

```{r mv-tot, fig.width=4, fig.height=4}
#| echo: !expr params$solve
ggplot(df, aes(x=mean, y=total)) +
    geom_point() +
    geom_point(data=fd, col="red") +
    geom_line(aes(y=tech), col="blue", lty=2)
```

The genes selected above correspond to genes with a large deviation from the baseline level of (technical) variation, i.e., they tend to have a large biological variance component:

```{r mv-var, echo=FALSE, fig.width=4, fig.height=4}
ggplot(df, aes(x=mean, y=bio)) +
    geom_point() +
    geom_point(data=fd, col="red") +
    geom_hline(yintercept=0, col="blue", lty=2)
```

### Dimension reduction

In standard scRNA-seq data anlysis pipelines, these "highly variable features" are subjected to principal component analysis (PCA) in order to identify major axes of variation. We can perform PCA on a `SingleCellExperiment` using `runPCA()` (`scater` package), where we specify the subset of features to use via argument `subset_row`:

```{r pca-calc}
# get selected features
length(sel <- rownames(fd))
# perform principal component analysis
sce <- runPCA(sce, subset_row=sel)
```

By default, `runPCA()` computes 50 PCs that are stored in the input object as a `reducedDim()` slot:

```{r pca-show}
# rows=cells, columns=PCs
pcs <- reducedDim(sce, "PCA")
pcs[1:5, 1:5]
dim(pcs) 
```

> Construct a `data.frame` that includes both, PCs and cell-level metdata (`colData`). Generate a scatter plot of PCs 1 and 2 as shown below, with cells colored by experimental condition and `cell` subpopulation, respectively; x and y axes should have a fixed aspect ratio! 

```{r plt-pca-stim, fig.width=5, fig.height=4}
#| echo: !expr params$solve
df <- data.frame(pcs, colData(sce))
ggplot(df, aes(PC1, PC2, col=stim)) +
    geom_point(size=0.2) + coord_equal() +
    guides(col=guide_legend(override.aes=list(size=2))) 
```

```{r plt-pca-cell, fig.width=6, fig.height=4}
#| echo: !expr params$solve
ggplot(df, aes(PC1, PC2, col=cell)) + 
    geom_point(size=0.2) + coord_equal() +
    guides(col=guide_legend(override.aes=list(size=2)))
```

It's pretty clear from the plots above that experimental condition (`stim`) and `cell` subpopulations seem to be considerable drivers of gene expression variability. But what is driving these differences? We can explore this visually by coloring cells by other cell metadata, e.g., library size (total sum of counts). 

> Generate a scatter plot of PCs 1 and 2 with cells colored by log-library size. Taking into consideration the plots generated above, what is the main driver of gene expression variation (PC1)?

```{r plt-pcs-ls}
#| echo: !expr params$solve
ggplot(df, aes(PC1, PC2, col=log10(sum))) +
    geom_point(size=0.2) + coord_equal() +
    scale_color_viridis_c()
```

Finally, note that the dataset retrieved from `ExperimentHub` already contains a non-linear embedding, t-SNE, that has been pre-computed by the original authors. We can access this representation as follows, and you are welcomed to explore visually exploring the data on your own, e.g., 

- color cells by gene expression (`logcounts()`)
- plot PCs (linear) again t-SNE dimensions (non-linear)
- `facet_wrap()` by `stim/ind/cell` to split plots according to some metadata variable

```{r eval=FALSE}
map <- reducedDim(sce, "TSNE")
df <- cbind(df, map)
ggplot(df, ...)
```

## Clustering scRNA-seq data

A standard approach to cluster scRNA-seq data is to (i) construct a graph where nodes = cells and edges = neighbors based on distances in, e.g., PCA space; and, (ii) finding communities of cells that are highly inter-connected. In other words: we want to link cells with each other based on their PCs to find *clusters* of transcriptionally similar cells.

```{r snn-louvain, message=FALSE, warning=FALSE}
# construct shared nearest neighbor (SNN) graph of cells
# using principal components 1-3 & based on Jaccard similarity 
# (see ?makeSNNGraph if you're interested in more details!)
g <- buildSNNGraph(sce, use.dimred="PCA", k=30, type="jaccard")
# use the Louvain algorithm to identify communities
# based on optimization of modularity (see ?cluster_louvain)
k <- cluster_louvain(g, resolution=0.5)$membership
```

We can visualize the resulting cellular graph as follows (for computational reasons, we'll use a representative subset of cells):

```{r plt-snn, fig.width=8, fig.height=8}
# sample at most 100 cells per cluster
i <- split(seq(ncol(sce)), k)
i <- lapply(i, \(.) sample(., min(50, length(.))))
# subset SNN graph & plot it
g_sub <- subgraph(g, unlist(i))
plot(g_sub, vertex.size=5, vertex.color="white") 
```

Now, we'll run the community detection step, which will return cluster assignments of each cell (accessible via `$membership` in the output object):

::: {.callout-note collapse="false"}

## Question

- How many *unique* clusters did we identify with the code above?  
- How does the number of clusters change when you decrease/increase the `resolution` parameter?  
- Compare the cluster assignments you get with available `cell` types using `table(old_cluster_IDs, new_cluster_IDs)`; can you guess, i.e., which cluster(s) correspond to B cells, CD4/8 T cells, etc.?

:::

Let's visualize the clustering results we obtain above, and compare them to previous results. To do this, we'll first construct a table (`data.frame`) containing all cell-information available to us at this point, i.e., cell metadata (`colData`), low-dimensional embeddings (`reducedDims`), and clustering results (`k` from the code above):

```{r prep-df-1}
df <- data.frame(
    k=factor(k),
    colData(sce), 
    reducedDim(sce, "PCA"),
    reducedDim(sce, "TSNE"))
```

::: {.callout-note collapse="false"}

## Question

Using the `data.frame` constructed above, visualize the t-SNE with cells colored by cluster assignment (`k`) and annotations (`cell`) using `ggplot`.

```{r plt-tsne-ks, fig.width=8, fig.height=3}
#| echo: !expr params$solve
#| eval: !expr params$solve
nk <- max(nlevels(df$k), nlevels(df$cell))
ggplot(df, aes(col=k)) + 
ggplot(df, aes(col=cell)) + 
plot_layout(nrow=1) &
    geom_point(aes(tsne1, tsne2), size=0.2) &
    guides(col=guide_legend(override.aes=list(size=2))) &
    scale_color_manual(values=hcl.colors(nk, "Spectral")) &
    theme_void() & theme(aspect.ratio=1, legend.key.size=unit(0.5, "lines"))
```

:::

In addition, we will add the expression (`logcounts`) of a few genes. Because `assay`s are stored with rows = genes and columns = cells, we need to transpose the expression matrix so that rows = cells using `t()`:

```{r prep-df-2}
gs <- c("MS4A1", "ISG15", "CD14")
es <- logcounts(sce)[gs, ]
es <- as.matrix(t(es))
df <- data.frame(df, es)
```

We can repeat the trick above, coloring cell by their expression of a given gene instead, e.g.:

```{r plt-tsne-es, echo=FALSE, fig.width=10, fig.height=3}
ggplot(df, aes(col=MS4A1)) + 
ggplot(df, aes(col=ISG15)) + 
ggplot(df, aes(col=CD14)) + 
plot_layout(nrow=1) &
    scale_color_gradientn(colors=c("navy", "red", "gold", "ivory")) &
    geom_point(aes(tsne1, tsne2), size=0.2) &
    theme(aspect.ratio=1) &
    theme_void() 
```

These type of visualizations are not ideal for many reasons (e.g., t-SNE is a non-linear embedding so that cell-cell distances are misleading, plots are too spacious when considering 100s of genes...). We could instead use, say, boxplots or heatmaps to understand different clusters' expression profiles. For the latter, we would first have to aggregate expression by each cluster, e.g., by computing the average:

```{r}
# split cell indices by cluster assignment
cs <- split(seq_len(ncol(sce)), k)
# count number of cells in each group
sapply(cs, length) 
# for each group of cells, subset 
# -> get exprs. (logcounts) 
# -> compute gene (row) means 
mu <- sapply(cs, \(.) rowMeans(logcounts(sce[, .])))
# rows = genes, columns = clusters
dim(mu)
```

We can visualize the results average expression by cluster using `pheatmap()`. Because genes can be expressed at very different levels of expression, we set `scale="row"` in order to scale each genes average expression to have zero mean and unit standard deviation across clusters: 

```{r fig.width=5, fig.height=3}
pheatmap(mu[gs, ], scale="row")
```

::: {.callout-note collapse="false"}

## Question

Based on the `table()` output comparing your and previous cluster assignments, and visualizing some genes you might know, can you annotated a few clusters (e.g., 1 = X cells, 2 = Y cells, 3 = Zocytes)?

:::

# Session info

```{r}
#| label: sessionInfo
sessionInfo()
```